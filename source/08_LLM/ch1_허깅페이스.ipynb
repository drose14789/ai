{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6edcfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\"\"\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input{font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML (\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\"\"\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input{font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202e4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "# 경고 제거\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# transformers 로깅 레벨 조정\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Hugging Face symlink 경고 제거\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# from transformers import pipeline, logging as hf_logging\n",
    "# hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a60bde",
   "metadata": {},
   "source": [
    "**<font size='6' color='red'>ch1_허깅페이스</font>**\n",
    "- Inference API 이용 : 모델의 결과를 server에서 \n",
    "- pipeline() 이용 : 모델을 다운로드 받아 모델의 결과를 local에서\n",
    "    * raw text -> tokenizer - > moedel -> [0.11, 0.55, 0.xx, ~] logits값으로 prediction 결과 출력\n",
    "\n",
    "```\n",
    "허깅페이스 transformers에서 지원하는 task\n",
    "\"sentiment-analysis\" : \"text-classification\"의 별칭(감정분석 적용)\n",
    "\"text-classification\" : 감정분석, 뉴스분류, 리뷰 분류 등 일반적인 문장 분류\n",
    "\"zero-shot-classification : 레이블을 학습 없이 주어진 후보군 중에서 분류\n",
    "\"token-classification\" : 개체명 인식(NER; Named Entity REcognition) 등 단위 라벨링\n",
    "\"ner\" : \"token-classification\"의 별칭\n",
    "\"fill-mask\" : 빈칸 채우기\n",
    "\"text-generation\" : 텍스트 생성 (GPT류 모델에 사용)\n",
    "\"text2text-generation\" : 번역, 요약 등 입력 -> 출력 변환\n",
    "\"translation\" : 번역\n",
    "\"summarization\" : 텍스트요약\n",
    "\"question-answering\" : 주어진 context를 보고 질문에 답하기.\n",
    "\"image-to-text\" : 그림을 설명\n",
    "\"image-classification\": 이미지분류\n",
    "```\n",
    "\n",
    "## 1. 텍스트 기반 감정분석(긍정/부정)\n",
    "- c:/사용자/내 컴퓨터명/.cache/huggingface/hub 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a285c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.951606810092926}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44006597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\",\n",
    "                     model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 감정분석시 내용이 많으면 list로\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c65a4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.857815682888031},\n",
       " {'label': 'POSITIVE', 'score': 0.9998846054077148}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"이 영화 정말 최고였어요. 감동적이고 연기가 대단해\",\n",
    "           \"This moive was the best. It's touching, and the acting is amazing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa4bd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8577604293823242}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"이 물건 정말 사고 싶어요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d13f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998695850372314},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079},\n",
       " {'label': 'NEGATIVE', 'score': 0.599323034286499},\n",
       " {'label': 'POSITIVE', 'score': 0.8669533729553223}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I like you\", \"I hate you\", \"나 너가 싫어\", \"힘들어요\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d859608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier=pipeline(task=\"sentiment-analysis\",\n",
    "                   model=\"matthewburke/korean_sentiment\")\n",
    "texts=(['나는 너가 좋아', \"당신이 싫어요\", \"힘들어요\", \"오늘 기분이 최고야\"])\n",
    "result= classifier(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e9086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 너가 좋아=>긍정 : 0.9558\n",
      "당신이 싫어요=>부정 : 0.9093\n",
      "힘들어요=>부정 : 0.9140\n",
      "오늘 기분이 최고야=>긍정 : 0.9714\n"
     ]
    }
   ],
   "source": [
    "for text, result in zip(texts, classifier(texts)):\n",
    "    label = \"긍정\"if result['label']=='LABEL_1' else \"부정\"\n",
    "    print(f\"{text}=>{label} : {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbcc51",
   "metadata": {},
   "source": [
    "## 2. 제로샷분류(Zero-shot분류)\n",
    "- 기계학습 및 자여넝 처리에서 각 개별 작업에 대한 특정 교육없이 작업을 수행할 수 있는 모형(비지도학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77920e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphoe that needs to be resloved asap!',\n",
       " 'labels': ['phone', 'urgent', 'computer', 'tablet', 'not urgent'],\n",
       " 'scores': [0.6687335968017578,\n",
       "  0.31948044896125793,\n",
       "  0.005518774501979351,\n",
       "  0.004069005139172077,\n",
       "  0.002198058646172285]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                     #model=\"facebook/bart-Large-mnli\"\n",
    "                     )\n",
    "classifier(\n",
    "    \"I have a problem with my iphoe that needs to be resloved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896c1aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'One dat I well see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9798721671104431, 0.011021879501640797, 0.009105958044528961]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequen_to_classify = \"One dat I well see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequen_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5af0c",
   "metadata": {},
   "source": [
    "## 3. text 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d577931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'in this course. We will teach you how to use virtual machine and Java to build a virtual machine that can run Windows. We will be able to write applications with a Java virtual machine on your home computer. We will be able to run Android applications on your home computer. We will be able to run Windows applications on your home computer. We will be able to use a virtual machine that will run Linux on your home computer.\\n\\nWe will be able to use a virtual machine that can run Windows on your home computer. We will be able to write applications with a Java virtual machine on your home computer. We will be able to run Android applications on your home computer. We will be able to run Windows applications on your home computer. We will be able to use a virtual machine that will run Linux on your home computer. Our course will address the following topics:\\n\\nHow to build a virtual machine that can run Java on your home computer\\n\\nHow to use Java as a virtual machine to write applications on your home computer\\n\\nHow to use virtual machines for your home computer to make use of Java Virtual Machines\\n\\nHow to create a virtual machine for your home computer\\n\\nHow to create a virtual machine for your home computer using Java Virtual Machines\\n\\nHow to use Java Virtual Machines to run Windows applications'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스 없음\n",
    "generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d17416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this course. We will teach you how to create your own tools and create your own projects.\n",
      "\n",
      "Learn to create your own projects\n",
      "\n",
      "This course will help you create your own projects in your own way.\n",
      "\n",
      "How to create your own projects:\n",
      "\n",
      "1. Find the right place\n",
      "\n",
      "A lot of people say that they are going to build a website. But what if you are just going to build a website and use a tool like Sketch or Illustrator? Now what if you just want to create your own website? How about using a tool like Paint? This course will show you how to create your own website using Sketch and Illustrator.\n",
      "\n",
      "2. Create your own project templates\n",
      "\n",
      "This is where you will learn how to create your own templates.\n",
      "\n",
      "3. Create your own templates\n",
      "\n",
      "The main idea of this course is to create a new project template. In this course, you will learn how to create your own templates.\n",
      "\n",
      "4. Create your own templates\n",
      "\n",
      "The main idea of this course is to create a new project template. In this course, you will learn how to create your own templates.\n",
      "\n",
      "5. Create your own templates\n",
      "\n",
      "You will create your own templates in this course. In this course, you will learn how to create your\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(\"text-generation\", \"gpt2\") # 텍스트 생성 gpt3부터는 허깅페이스 없음\n",
    "result = generation(\n",
    "    \"in this course. We will teach you how to\",\n",
    "    pad_token_id=generation.tokenizer.eos_token_id\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd9f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 과정은 다음과 같은 방법을 알려드려요.\" 하고 말하고 다시 한 번 \"내 말이 정말입니까?\" 하며 이 말을 되풀이합니다.\n",
      "어떤 사람은 이 일을 해냈습니다.\n",
      "어떤 이는 \"내가 일을 했다고 해. 그럼 네가 그 일을 하도록 했느냐?\"고 질문합니다.\n",
      "그러나 그는 그 말을 믿지 못하죠.\n",
      "그러니 그 일은 일어나지 않았습니다.\n",
      "'네가 왜 그랬을까?'는 질문에는 아무런 대답도 하지 않아요.\n",
      "그리고 어떤 사람은 네 자신을 이해할 수 없는 것 같습니다.\n",
      "그래서 네게 '넌 왜 그래, 아니면 나는?'\n"
     ]
    }
   ],
   "source": [
    "generation = pipeline(\"text-generation\", \"skt/kogpt2-base-v2\")\n",
    "result = generation(\n",
    "    \"이 과정은 다음과 같은 방법을 알려드려요.\",\n",
    "    pad_token_id = generation.tokenizer.eos_token_id,\n",
    "    max_new_tokens = 100, # 생성할 최대 길이(생성할 토큰 수)\n",
    "    num_return_sequences=1, # 생성할 문장 갯수\n",
    "    do_sample=True, # 다양한 샘플 사용\n",
    "    top_k=50, # top-k 샘플링(확률 높은 상위 50개 토큰만 사용)\n",
    "    top_p=0.95, #확률이 높은 순서대로 95% 될 때까지의 단어들로만 후보로 사용\n",
    "    temperature=1.2, # 창의성 조절(낮을 수록 보수적)\n",
    "    no_repeat_ngram_size=2 # 반복 방지\n",
    ")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6c0fc",
   "metadata": {},
   "source": [
    "## 4. 마스크(빈칸)채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b4ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19275707006454468,\n",
       "  'token': 3299,\n",
       "  'token_str': ' doctor',\n",
       "  'sequence': \"I'm going to hospital and meet a doctor\"},\n",
       " {'score': 0.06794589757919312,\n",
       "  'token': 27321,\n",
       "  'token_str': ' psychiatrist',\n",
       "  'sequence': \"I'm going to hospital and meet a psychiatrist\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task='fill-mask',\n",
    "                   model='distilbert/distilroberta-base') # 마스크 채우기\n",
    "unmasker(\"I'm going to hospital and meet a <mask>\", top_k=2) # top_k 기본값 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7bb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unmasker(\"병원에 가서 <mask>를 만날 거예요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f65b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0629730075597763,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': \"Hello, I'm a business model.\"},\n",
       " {'score': 0.038101598620414734,\n",
       "  'token': 18150,\n",
       "  'token_str': ' freelance',\n",
       "  'sequence': \"Hello, I'm a freelance model.\"},\n",
       " {'score': 0.03764132782816887,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': \"Hello, I'm a role model.\"},\n",
       " {'score': 0.037326786667108536,\n",
       "  'token': 2734,\n",
       "  'token_str': ' fashion',\n",
       "  'sequence': \"Hello, I'm a fashion model.\"},\n",
       " {'score': 0.026023676618933678,\n",
       "  'token': 24526,\n",
       "  'token_str': ' Playboy',\n",
       "  'sequence': \"Hello, I'm a Playboy model.\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello, I'm a <mask> model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dc445d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14130638539791107,\n",
       "  'token': 35,\n",
       "  'token_str': ':',\n",
       "  'sequence': '안녕하세요? 나는: 모델이예요.'},\n",
       " {'score': 0.1223798543214798,\n",
       "  'token': 116,\n",
       "  'token_str': '?',\n",
       "  'sequence': '안녕하세요? 나는? 모델이예요.'},\n",
       " {'score': 0.08188082277774811,\n",
       "  'token': 328,\n",
       "  'token_str': '!',\n",
       "  'sequence': '안녕하세요? 나는! 모델이예요.'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"안녕하세요? 나는 <mask> 모델이예요.\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "396641e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1441437155008316,\n",
       "  'token': 2535,\n",
       "  'token_str': 'role',\n",
       "  'sequence': \"hello, i ' m a role model.\"},\n",
       " {'score': 0.14175789058208466,\n",
       "  'token': 4827,\n",
       "  'token_str': 'fashion',\n",
       "  'sequence': \"hello, i ' m a fashion model.\"},\n",
       " {'score': 0.062214579433202744,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': \"hello, i ' m a new model.\"},\n",
       " {'score': 0.041028350591659546,\n",
       "  'token': 3565,\n",
       "  'token_str': 'super',\n",
       "  'sequence': \"hello, i ' m a super model.\"},\n",
       " {'score': 0.025911200791597366,\n",
       "  'token': 2449,\n",
       "  'token_str': 'business',\n",
       "  'sequence': \"hello, i ' m a business model.\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(task=\"fill-mask\",\n",
    "                   model=\"google-bert/bert-base-uncased\")\n",
    "unmasker(\"Hello, I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00429401",
   "metadata": {},
   "source": [
    "# ※ InferenceAPI 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1f9575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "#os.environ['HF_TOKEN']\n",
    "# 허깅페이스 토큰을 Read권한으로 생성하여 .env에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab948889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
