{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf8cd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\"\"\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input{font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML (\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\"\"\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input{font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cff31",
   "metadata": {},
   "source": [
    "**<font size='6' color='red'>ch2.Ollama_LLM활용의 기본 개념</font>**\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용\n",
    "- 성능은 GPT, CLaude 같은 모델보다 떨어지나, 개념 설명을 위해 open source 모델 사용\n",
    "\n",
    "#### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- cmd창이나 powershell 창에 ollama run deepseek-r1:1.5b\n",
    "\n",
    "https://docs.langchain.com/oss/python/integrations/chat/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d52bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of Korea is South Korea.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-12-10T00:13:08.0442177Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2274310400, 'load_duration': 1708483100, 'prompt_eval_count': 10, 'prompt_eval_duration': 183283000, 'eval_count': 13, 'eval_duration': 339748600, 'logprobs': None, 'model_name': 'deepseek-r1:1.5b', 'model_provider': 'ollama'}, id='lc_run--019b059a-bd5f-7da2-85c1-c37955a3170d-0', usage_metadata={'input_tokens': 10, 'output_tokens': 13, 'total_tokens': 23})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e1bf4",
   "metadata": {},
   "source": [
    "### 모델 pull\n",
    "- cmd창이나 powershell(window키+R에서 powershell)창에서 ollama pull llama3.2:1b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdf8136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that there are two separate countries in East Asia with similar names: North Korea and South Korea. The former is a sovereign state, while the latter is a de facto independent country under the North Korean regime.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T05:27:33.4001027Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4789196400, 'load_duration': 2400901500, 'prompt_eval_count': 32, 'prompt_eval_duration': 305738900, 'eval_count': 56, 'eval_duration': 2025422700, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b0194-3461-7d60-b6c5-4fe7a1c5b129-0', usage_metadata={'input_tokens': 32, 'output_tokens': 56, 'total_tokens': 88})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a440434b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f41bc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국 수도는 서울입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T02:18:27.4108221Z', 'done': True, 'done_reason': 'stop', 'total_duration': 375905200, 'load_duration': 124266200, 'prompt_eval_count': 32, 'prompt_eval_duration': 34638000, 'eval_count': 7, 'eval_duration': 209332900, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b00e7-2559-72c2-b3c8-5f5471382db1-0', usage_metadata={'input_tokens': 32, 'output_tokens': 7, 'total_tokens': 39})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=llm.invoke(\"한국 수도가 어디에요?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd9ac1",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    "- pip install langchain-openai\n",
    "- https://auth.openai.com/log-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c4151b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()\n",
    "#os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f134047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\",\n",
    "                #api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "result = llm.invoke(\"What is the capital of Korea? Return the name of the city only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c187bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seoul', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 21, 'total_tokens': 416, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ckkafp5cv4PaJ7WJKdRsSOt1qM4XS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b0196-c55e-7d12-85bc-c81584e8cc4d-0', usage_metadata={'input_tokens': 21, 'output_tokens': 395, 'total_tokens': 416, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8481024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure : OPENAI_API_VERSION키값\n",
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24963836",
   "metadata": {},
   "source": [
    "# 2. LangChain 스타일로 프롬프트 작성\n",
    "- 프롬프트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fdac6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# PromptValue, str, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6af95",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f9f283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of KOREA?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that North Korea shares a border with South Korea and also claims Seoul as its own capital. This dual capital status can be confusing, but technically, Pyongyang (the capital of North Korea) is the de facto seat of government.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T05:47:53.781774Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4266435700, 'load_duration': 1714967000, 'prompt_eval_count': 34, 'prompt_eval_duration': 322956700, 'eval_count': 60, 'eval_duration': 2163762600, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01a6-d58a-7ef1-82de-cd2c3c954286-0', usage_metadata={'input_tokens': 34, 'output_tokens': 60, 'total_tokens': 94})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "#country = input('어느 나라의 수도를 알고 싶은신가요?')\n",
    "prompt = prompt_template.invoke({\"country\":\"KOREA\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16800dd",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "- vscode에서 ctrl+shift+p : python:select interpreter입력 -> python환경선택\n",
    "- vscode에서 커널 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c750d411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"South Korea's capital is Seoul, while North Korea has its own capital, Pyongyang.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:04:54.5583153Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2851150500, 'load_duration': 1475743200, 'prompt_eval_count': 86, 'prompt_eval_duration': 725813900, 'eval_count': 18, 'eval_duration': 629986500, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01b6-6e78-7951-97dc-311f6af83437-0', usage_metadata={'input_tokens': 86, 'output_tokens': 18, 'total_tokens': 104})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"), # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Paris.\"), # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of Korea?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b63997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of {country}?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "print(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474d2a4",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage리스트 -> 튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60c2def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요korea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The capital of South Korea is Seoul. However, the official name of the country is the Republic of Korea (ROK), and its government is divided between Seoul, which serves as the de facto capital, and the Democratic People's Republic of Korea (DPRK), which serves as the de jure capital.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage 리스트를 수정\n",
    "# PromptTemplate : 프롬프트에 변수포함, \n",
    "# ChatPromptTemplate : SystemPrompt설정(페르소나), few shot설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpfull assistant!\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of France is Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "#print(\"프롬프트 : \", prompt, type(prompt))\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9952c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, the official name of the country is the Republic of Korea (ROK), and its government is divided between Seoul, which serves as the de facto capital, and the Democratic People's Republic of Korea (DPRK), which serves as the de jure capital.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:55:03.3495884Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4541571300, 'load_duration': 1403412300, 'prompt_eval_count': 88, 'prompt_eval_duration': 678506000, 'eval_count': 64, 'eval_duration': 2371673900, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01e4-50f6-74b0-b62b-d1c5b7ff0c58-0', usage_metadata={'input_tokens': 88, 'output_tokens': 64, 'total_tokens': 152})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8d669",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤하기\n",
    "- llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870c219",
   "metadata": {},
   "source": [
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcef435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시하상이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\": \"Korea\"})\n",
    "#print(prompt)\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message)\n",
    "# 문자열 출력 파서를 이용하여 llm응답(AIMesaage 객체)을 단순 문자열로 변환\n",
    "output_parser = StrOutputParser()\n",
    "result = output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d04f6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d25a90d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chatPrompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\") #Return the name of the city only\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chatPrompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752abae",
   "metadata": {},
   "source": [
    "## 2) Json 출력 파서 이용\n",
    "- {'name':'홍길동', 'age':22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6a7bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51.8, 'language': 'Korean', 'currency': 'South Korean won'} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detalil_prompt = PromptTemplate(\n",
    "    template = \"\"\" \n",
    "    Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "prompt = country_detalil_prompt.invoke({\"country\":\"Korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "#print(ai_message)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result, type(json_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c3a278a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Tokyo',\n",
       " 'population': 128731097,\n",
       " 'language': 'Japanese',\n",
       " 'currency': 'Yen'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detalil_prompt.invoke({\"country\": \"Japen\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395df35",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : 데이터유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d5b3632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x000002637147A140>\n"
     ]
    }
   ],
   "source": [
    "class User :\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(1, \"홀길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57635e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    id : int = Field(gt=0, description=\"id\")\n",
    "    name : str = Field(min_length=2, description=\"name\")\n",
    "    is_active: bool = Field(default=True, description=\"id활성화 여부\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cf2a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51000000, language='Korean', currency='South Korean won')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detalil_prompt = PromptTemplate(\n",
    "    template = \"\"\" \n",
    "    Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "class CountryDetail(BaseModel): # description : 더 정확한 출력 유도\n",
    "    capital:str = Field(description=\"the Capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language : str = Field(description=\"the language of the country\")\n",
    "    currency:str = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info = structedllm.invoke(country_detalil_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "908df053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "002f91b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51000000, 'Korean', 'South Korean won')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e374c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json으로 : {\"capital\":\"Seoul\",\"population\":51000000,\"language\":\"Korean\",\"currency\":\"South Korean won\"}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'South Korean won'}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json으로 :\", info.model_dump_json())\n",
    "print(\"info를 dict로 :\", info.__dict__)\n",
    "print(\"info를 dict로 :\", info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47cd47",
   "metadata": {},
   "source": [
    "# 4. LCEL 활용한 LangChain 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke\n",
    "- StrOutputParser, ChatOllama, PromptTemplate등은 모두 Runnable로 상속 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d28c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a1a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",\n",
    "                temperature=0) # 일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only.\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() # AIMessage()를 Str변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec359b08",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 피아프연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bd4c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> LLM -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\": \"Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61885a6",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    "- 여러 단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f24921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라 이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"Guess the name of the country based on the following informat:\n",
    "    {information}\n",
    "    Return the name of the country only\n",
    "    \"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\": \"This country is very famous for its wine\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eee4987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chaifn.invoke({\"information\": \"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dab7771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인 : 나라설명 -> 나라명(country_chain)\n",
    "#                        나라명 -> 수도(capital_chain)\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5d8cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\":RunnablePassthrough()} | \\\n",
    "               {\"country\": country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b81687bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\"This country is very famous for its wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33dea3",
   "metadata": {},
   "source": [
    "- 한글 지원이 안 되는 모델은 렝체인 연결이 잘 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2a103a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 나라는 와인으로 유명해\\n\\n1. 프랑스 - burgundy, merlot, cabernet sauvignon\\n2. 이탈리아 - chianti, pinot noir, vermentino\\n3. 스태프lein만 - merlot, cabernet sauvignon, syrah\\n4. 이스라엘 - shiraz, carmenère, pinot noir\\n5. 독일 - riesling, pinot noir, gruner veltliner'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"다음의 {information} 설명을 보고 나라이름을 맞춰봐:\n",
    "    {information}\n",
    "    나라 이름만 한국어로 reutrn 해 줘\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                            \"이 나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18714dcd",
   "metadata": {},
   "source": [
    "# 5. 생성형 AI 평가: 나라이름 -> 그 나라에서 제일 유명한 음식의 레시피를 출력하는 복합체인 구현\n",
    "- 위 : (나라설명 -> 나라이름 -> 수도 (체인두개 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "017ef33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : 나라명 -> 그 나라에서 제일 유명한 음식(fodd_chain)\n",
    "#                        음식 -> 레시피(recipe_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c695349",
   "metadata": {},
   "source": [
    "## 1) LLM 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deeba2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Temperature를 0으로 설정하여 일관된 답변 유도\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99395030",
   "metadata": {},
   "source": [
    "## 2) 음식 추천 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61acbda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bibimbap.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음식 이름 찾기\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 음식 이름만 반환하도록 명확하게 지시\n",
    "food_prompt = PromptTemplate(\n",
    "    template='''what is one of the most popular food in {country}? \n",
    "        Please return the name of the food only''', # token아끼자\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "# 음식 추천 체인 구성\n",
    "food_chain = food_prompt | llm | StrOutputParser()\n",
    "# 음식 추천 체인 실행\n",
    "food_chain.invoke({'country': 'South Korea'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d2664",
   "metadata": {},
   "source": [
    "## 3) 레시피 생성 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b518d5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a traditional Korean recipe for Bibimbap:\\n\\n1. Prepare the ingredients:\\n\\t* 8 oz. mixed vegetables (zucchini, carrots, bean sprouts)\\n\\t* 1 cup cooked white rice\\n\\t* 2 eggs, fried or poached\\n\\t* 1/2 cup diced beef (or tofu for a vegetarian option)\\n\\t* 1/4 cup chopped green onions\\n\\t* 1/4 cup toasted sesame seeds\\n\\t* 2 tbsp. soy sauce\\n\\t* 1 tsp. Gochujang (Korean chili paste)\\n\\t* Salt and pepper to taste\\n\\t* Vegetable oil for frying\\n\\n2. Cook the rice:\\n\\t* Rinse the rice thoroughly and cook according to package instructions.\\n\\t* Allow the rice to cool.\\n\\n3. Prepare the vegetables:\\n\\t* Cut the mixed vegetables into bite-sized pieces.\\n\\t* Slice the egg into thin wedges.\\n\\n4. Assemble the Bibimbap:\\n\\t* Divide the cooked rice onto a plate or bowl.\\n\\t* Arrange the mixed vegetables, diced beef (or tofu), and fried egg in the center of the rice.\\n\\t* Drizzle with soy sauce and Gochujang.\\n\\t* Garnish with chopped green onions and toasted sesame seeds.\\n\\n5. Serve:\\n\\t* Serve immediately and enjoy!\\n\\nNote: Traditionally, Bibimbap is served with a variety of toppings, such as kimchi (spicy fermented Korean cabbage) or pickled ginger. Feel free to customize your dish to your liking!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 메시지를 통해 레시피 형식 지정\n",
    "recipe_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Provide the recipe of the food that the user wants. \n",
    "Please return the recipe only as a numbered list without any explanation'''), #input token보다 output token이 비쌈\n",
    "    ('human', 'Can you give me the recipe for making {food}?')\n",
    "])\n",
    "\n",
    "# 레시피 생성 체인 구성\n",
    "recipe_chain = recipe_prompt | llm | StrOutputParser()\n",
    "# 레시피 생성 체인 실행\n",
    "recipe_chain.invoke({'food': 'Bibimbap'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde7fe2",
   "metadata": {},
   "source": [
    "## 4) 체인 연결을 통한 최종 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb23966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a traditional Korean recipe for Bibimbap:\n",
      "\n",
      "1. Cook the rice:\n",
      "\t* Rinse 2 cups of white or brown rice and cook according to package instructions.\n",
      "\t* Allow the rice to cool down to room temperature.\n",
      "\n",
      "2. Prepare the vegetables:\n",
      "\t* Slice 1 cup of zucchini, 1 cup of carrots, and 1 cup of bean sprouts.\n",
      "\t* Thinly slice 1/2 cup of shiitake mushrooms.\n",
      "\t* Dice 1/4 cup of cucumber.\n",
      "\n",
      "3. Prepare the meat (optional):\n",
      "\t* Slice 1/2 cup of beef (thinly sliced) or tofu for a vegetarian option.\n",
      "\n",
      "4. Assemble the Bibimbap:\n",
      "\t* Divide the cooked rice into 4-6 portions, depending on serving size.\n",
      "\t* Arrange the vegetables and meat (if using) in the center of each portion.\n",
      "\t* Place a fried egg on top of the vegetables.\n",
      "\n",
      "5. Drizzle with sauce:\n",
      "\t* Mix 2 tablespoons of Gochujang (Korean chili paste), 1 tablespoon of soy sauce, and 1 tablespoon of rice vinegar.\n",
      "\t* Brush the sauce over the Bibimbap.\n",
      "\n",
      "6. Serve immediately:\n",
      "\t* Garnish with toasted sesame seeds and chopped green onions.\n",
      "\t* Serve hot and enjoy!\n",
      "\n",
      "Note: You can customize your Bibimbap to your liking by adding other ingredients such as diced kimchi, pickled ginger, or a sprinkle of crispy garlic.\n"
     ]
    }
   ],
   "source": [
    "# 음식 추천과 레시피 생성을 연결한 최종 체인 구성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = food_chain | recipe_chain\n",
    "# final_chain = {\"country\":RunnablePassthrough()}| food_chain | recipe_chain\n",
    "# final_chain = {\"country\":RunnablePassthrough()}|{'food': food_chain} | recipe_chain\n",
    "# 국가 입력으로 대표 음식을 찾고, 해당 음식의 레시피까지 자동으로 생성\n",
    "recipe = final_chain.invoke(\"Korea\")\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1324b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
