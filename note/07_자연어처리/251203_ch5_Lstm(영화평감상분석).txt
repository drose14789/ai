LSTM
- 기존 코드와 크게 다른점이 없고 모형을 만드는 클래스가 바뀌었음

단어 임베딩
- Sparse vector를 dense vector로 전환
    - 원핫인코딩(sparse): 너무 비효율적
    - Word embedding(sense) : 메모리 사용과 계산 속도를 획기적으로 단축

GNMT 기술 LSTM으로 영어-한글 번역하기
- Google Neural Machine Translation(GNMT)
    - RNN 기반 sequence-to-sequence 방식
    - 인코더/디코더 연결 구조
    -  인코더 : 입력 문장
    -  디코더 : 출력 문장
    -  응용 : 번역, 챗봇