1. OpenAI Assistants API 소개
OpenAI Assistants API는 OpenAI의 새로운 API로, 대화형 AI 어시스턴트를 보다 쉽게 구축하고 
관리할 수 있도록 설계되었음. 기존의 Chat Completion API가 무상태(stateless) 방식이어서 매 
요청마다 대화 기록을 모두 보내야 했다면, Assistants API는 상태를 유지(stateful) 하는 
대화 스레드(Thread)를 제공하여 자동으로 대화 컨텍스트를 관리. 또한 함수 호출, 코드 실행, 
지식 검색 등의 도구(Tools) 를 어시스턴트에 병렬로 연결할 수 있어 훨씬 강력한 
코파일럿(copilot) 형태의 서비스를 구축할 수 있음.

- 대화 지속성 & 메모리: Assistants API는 대화 스레드에 메시지 내역을 지속적으로 저장하며, 
컨텍스트 윈도우 제한 내에서 자동으로 요약/잘라내기를 수행. 개발자는 별도의 상태 관리 로직 없이 
장기간의 대화도 처리할 수 있음.
- 다양한 도구 통합: 어시스턴트가 코드 실행(Code Interpreter), 지식 검색(File Retrieval), 
함수 호출(Function Calling) 등의 도구를 직접 사용하도록 구성할 수 있음. 이를 통해 모델의 한계를 
넘어서는 작업(예: 데이터베이스 질의, 파일 처리, 외부 API 호출 등)을 자동화할 수 있음.
- 개인화된 지시어: 어시스턴트를 생성할 때 지시어(Instructions) 를 주입함으로써 해당 어시스턴트의 
성격과 역할을 미리 정의할 수 있음. 예를 들어 “당신은 친절한 고객지원 봇입니다”와 같은 시스템 
지시어로 어시스턴트의 톤과 도메인 지식을 설정할 수 있음.
- 개발 편의: OpenAI 플랫폼의 웹 인터페이스(플레이그라운드)뿐 아니라 API를 통해서도 동일한 
어시스턴트를 생성/관리할 수 있음. 한 번 만든 어시스턴트를 재사용하거나 여러 쓰레드를 동시에 
운영하는 것이 쉬워짐. (예: 하나의 어시스턴트에 대해 다수의 사용자 대화 스레드를 관리)

요약하면, Assistants API는 기존 ChatGPT API의 상태 관리 진화판으로 볼 수 있음. 복잡한 대화 상태 
관리, 외부 도구 통합, 문서 임베딩 등 많은 부분을 OpenAI 플랫폼이 맡아주므로, 개발자는 핵심 로직
구현에 집중할 수 있음. 이러한 이유로, 코파일럿 스타일의 챗봇이나 자동화 에이전트를 만든다면 
Assistants API가 강력한 선택지가 됨

Note: Assistants API는 2025년 초 현재 베타(beta) 단계로, OpenAI가 지속적으로 기능을 개선하고 
있음. 사용 전에 최신 문서를 확인하고, 베타 API인 만큼 일부 동작이나 요금 정책이 변경될 수 있음을
유의.

2.API 키 설정 및 환경 변수 사용
OpenAI API를 사용하려면 API 키가 필요. OpenAI 플랫폼의 API 키 관리 페이지에서 비밀 키를 
생성할 수 있음. 생성된 키는 한 번만 표시되므로, 반드시 복사하여 안전한 곳에 저장. 일반적으로 
이 키를 소스 코드에 하드코딩하지 않고, 별도의 설정으로 관리하는 것이 좋음. 
**환경 변수(Environment Variable)**를 사용하면 API 키를 소스 코드에 노출하지 않고 관리할 수 
있음. 개발 PC 또는 서버의 환경 변수 OPENAI_API_KEY에 키를 저장해 두면, OpenAI 라이브러리가 
자동으로 이를 읽어 사용할 수 있음. Python 개발 환경에서는 python-dotenv 패키지를 활용해 
.env 파일에 키를 저장하고 로드하는 방식이 편리.

다음은 API 키를 설정하고 로드하는 과정:

python-dotenv 설치: 터미널에서 pip install python-dotenv 명령으로 설치합니다 (한번만 수행).

환경 변수 파일 생성: 프로젝트 루트 디렉토리에 .env 파일을 만들고, 아래와 같이 OpenAI API 키를 
입력 (따옴표 없이 실제 키로 대체).

	OPENAI_API_KEY=sk-***********************

코드에서 로드: Python 코드에서 python-dotenv를 이용해 .env를 로드하고, os.environ을 통해 키를 
불러옴. OpenAI 공식 Python SDK에서는 환경 변수 OPENAI_API_KEY를 자동으로 인식하므로, 
명시적으로 지정하지 않아도 동작

3. 기본적인 Assistant 생성 및 메시지 보내기

어시스턴트는 대화를 수행하는 주체로, 사용자의 요청을 받아 처리하는 AI 에이전트라고 볼 수 있음. 
Assistants API에서 어시스턴트를 생성할 때는 어떤 모델을 사용할지, 어떤 지시어(Instructions)를 
가질지, 그리고 사용할 **툴(Tools)**이 무엇인지 등을 설정할 수 있음.

주요 파라미터를 살펴보면:

name: 어시스턴트의 이름을 지정합니다. 콘솔이나 리스트에서 구분하기 위한 용도이며, 모델 응답 
내용에는 영향을 미치지 않음.

instructions: 시스템 레벨의 지시어로, 해당 어시스턴트가 모든 대화에서 따르게 될 기본 규칙이나 
역할을 정의. 여기서는 "친절한 도움말 어시스턴트"라는 성격을 부여. 
(이 지시어는 기존 ChatGPT의 시스템 메시지와 유사한 역할.)

model: 어시스턴트가 사용할 언어 모델을 지정. 최신 기능을 쓰려면 OpenAI가 Nov 2023 이후 
출시한 모델(-1106가 붙은 모델명)을 권장.

assistant 생성을 제공하는 모델 GPT-4 계열: gpt-4 - 기본 GPT-4 모델 
gpt-4-turbo - 더 빠르고 효율적인 GPT-4 gpt-4o - 최신 멀티모달 모델 
gpt-4o-mini - 경량화된 GPT-4o

GPT-3.5 계열: gpt-3.5-turbo - 빠르고 효율적인 모델(추천)

기타: dall-e-3 - 이미지 생성용 whisper-1 - 음성 인식용 tts-1, tts-1-hd - 텍스트 음성 변환용

tools: 어시스턴트에 활성화할 도구 목록. 기본적인 Q&A 챗봇에서는 특별한 툴이 필요 
없으므로 비워두었음. (tools=[] 또는 생략) 나중에 코드 인터프리터나 함수 호출 등을 사용하게 
될 경우 이 필드를 설정.
어시스턴트가 성공적으로 생성되면 고유 ID (assistant.id)가 반환. 이 ID는 이후 대화 스레드에서 
어떤 어시스턴트를 사용할지 지정할 때 필요하므로 저장해둠. 
(참고로, client.beta.assistants.list()를 호출하면 계정 내 모든 어시스턴트 목록을 확인할 수 있음.)

- client.beta.threads.create(): 새로운 대화 스레드를 생성합. 
  반환된 thread 객체는 고유 ID (thread.id)를 갖음.

- client.beta.threads.messages.create(...): 특정 스레드에 새로운 메시지를 추가. 
  role 파라미터로 이 메시지의 주체를 지정하는데, 사용자 메시지이므로 "user"로 설정하고 
  content에 사용자의 질문 내용을 넣음.

- client.beta.threads.runs.create_and_poll(...): 해당 스레드를 주어진 어시스턴트로 실행(run). 
  assistant_id를 우리가 생성한 어시스턴트의 ID로 지정해야 함. 여기서는 create_and_poll를 사용하여
  실행이 완료될 때까지 블록. 
  (이 함수는 내부적으로 주기적으로 run.status를 체크하여 완료될 때까지 기다림.)

    >참고: create_and_poll를 사용하지 않고 runs.create를 쓰는 경우, 즉시 run 객체를 받고 
    수동으로 상태를 확인해야 함. 간단한 예에서는 편의를 위해 create_and_poll로 
    한 번에 처리했음.

- 대화 실행이 완료되면 (run.status == "completed") 해당 스레드에는 사용자 질문과 어시스턴트 
  답변, 총 두 개의 메시지가 들어있게 됩니다. 이를 threads.messages.list로 가져와서 출력.

어시스턴트가 우리의 지시어에 따라 친절한 톤으로 답변한 것을 볼 수 있음. 
이처럼 스레드 생성 -> 메시지 추가 -> 실행 -> 결과 조회의 흐름으로 어시스턴트와의 기본 대화를 
구현할 수 있음.

4. 파일 업로드 및 코드 인터프리터 활용

OpenAI Assistants API에서 파일 업로드는 사용자가 제공한 데이터를 어시스턴트가 활용할 수 있게 
하는 중요한 기능. 예를 들어 PDF 문서를 요약하거나, CSV 데이터를 분석하거나, 이미지를 처리하는 
등의 작업이 가능해짐. Assistants API에서는 파일을 미리 업로드하고 file ID를 통해 어시스턴트와 
대화 스레드에 첨부하는 방식을 사용. 이렇게 첨부된 파일들은 어시스턴트의 도구를 통해 접근할 수 
있음. 

파일을 다루는 대표적인 도구로 **코드 인터프리터(Code Interpreter)**가 있음. 코드 인터프리터를 
활성화하면 어시스턴트는 Python 코드를 작성하고 실행하여 결과를 산출할 수 있게 됨. 
이때 외부 파일이 필요하면, 사전에 업로드된 파일을 코드에서 읽거나 쓸 수 있음. 

OpenAI Python SDK에서는 client.files.create 메서드를 제공하며, 여기에 파일 객체와 용도를 
지정하여 업로드할 수 있음. 파일 용도는 purpose='assistants'로 설정해야 Assistants API 대화에서 
활용 가능한 리소스로 저장. 한 번 업로드된 파일은 OpenAI 서버에 저장되며, 반환되는 file.id를 
이용해 어시스턴트나 스레드에 첨부할 수 있음.

- OpenAI Assistants API에서 사용 가능한 주요 모델

> GPT-4 모델군
gpt-4o - 최신 GPT-4 Omni 모델 (텍스트, 이미지, 오디오 처리 가능)
gpt-4o-mini - GPT-4 Omni의 경량화 버전 (비용 효율적)
gpt-4-turbo - GPT-4 Turbo 모델
gpt-4 - 기본 GPT-4 모델

>GPT-3.5 모델군
gpt-3.5-turbo - GPT-3.5 Turbo 모델

>코드 인터프리터 사용 시 권장 모델
코드 인터프리터를 사용하는 데이터 분석 작업의 경우:
gpt-4o - 가장 강력한 성능, 복잡한 분석 작업에 최적
gpt-4o-mini - 비용 대비 성능이 우수, 일반적인 데이터 분석에 적합
gpt-4-turbo - 안정적인 성능, 대용량 데이터 처리에 좋음


코드 인터프리터를 활용하면 어시스턴트가 사용자 제공 데이터를 직접 분석하거나 처리한 후 결과를 
알려줄 수 있음. ChatGPT의 Code Interpreter 기능을 API로 사용할 수 있게 된 셈. 
이미지 처리, 데이터 시각화, 파일 변환 등 다양한 작업을 자동화할 수 있으므로 활용 범위가 매우 
넓음.

>Tips: 코드 인터프리터 사용 시 고려사항:
- 실행 시간: 코드 실행에는 시간이 걸릴 수 있음. runs.create_and_poll를 쓰면 자동으로 대기해주지만
, 복잡한 작업의 경우 타임아웃이나 지연을 염두에 두어야 함.

- 파일 접근: 첨부된 파일들은 코드 인터프리터 세션 내에서 읽기/쓰기 가능함. 어시스턴트가 새로운 
  파일(예: 그래프 이미지)을 생성하면, 그 파일도 자동으로 OpenAI 파일 스토리지에 업로드되고 
  ID가 부여됨. 어시스턴트의 답변에는 해당 파일 ID가 인용 형태로 포함될 수 있음.
 (예: “보고서 결과는 파일 file_xyz에 저장되었습니다.”) 이러한 파일은 client.files.list() 등을 통해 
 확인할 수 있음.

- 보안: 코드 인터프리터는 격리된 샌드박스 환경에서 동작하므로 어시스턴트가 인터넷에 직접 
  접속하거나 로컬 시스템에 영향을 주지 않음. 다만, 악성 코드나 무한 루프 등으로 오남용되지 
  않도록 OpenAI 측에서 실행 시간을 제한하고 있음을 참고.
